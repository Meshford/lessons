{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† –£—Ä–æ–∫ 26: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤–∏–¥–µ–æ –∏ —Ç–µ–∫—Å—Ç–∞\n",
        "**–¶–µ–ª—å —É—Ä–æ–∫–∞:** –ù–∞—É—á–∏—Ç—å—Å—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ –∏ —Ç–µ–∫—Å—Ç. –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤.\n",
        "\n",
        "## üìå –ü–æ—á–µ–º—É –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–Ω—ã–µ?\n",
        "- **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** –ú–∞—Ç—Ä–∏—Ü—ã –ø–∏–∫—Å–µ–ª–µ–π, –≥–¥–µ –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å ‚Äî —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞.\n",
        "- **–í–∏–¥–µ–æ:** –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–¥—Ä–æ–≤ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π), –≥–¥–µ –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä –∏–º–µ–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É.\n",
        "- **–¢–µ–∫—Å—Ç:** –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ–≤, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ —á–∏—Å–ª–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ML.\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ ‚Äî —ç—Ç–æ –∫–Ω–∏–≥–∏, —Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî —ç—Ç–æ —Ä–æ–º–∞–Ω—ã, –≤–∏–¥–µ–æ ‚Äî —ç–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏–∏, –∞ —Ç–µ–∫—Å—Ç ‚Äî —É—á–µ–±–Ω–∏–∫–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìê –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
        "- **–§–æ—Ä–º–∞—Ç—ã:** JPEG (—Å–∂–∞—Ç–∏–µ —Å –ø–æ—Ç–µ—Ä—è–º–∏), PNG (–±–µ–∑ –ø–æ—Ç–µ—Ä—å), BMP (—Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ).\n",
        "- **–ß—Ç–µ–Ω–∏–µ:**\n",
        "  ```python\n",
        "  from PIL import Image\n",
        "  img = Image.open('example.jpg')\n",
        "  print(img.size)  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "  ```\n",
        "- **–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞:**\n",
        "  ```python\n",
        "  resized_img = img.resize((100, 100))  # –ò–∑–º–µ–Ω–∏—Ç—å –¥–æ 100x100\n",
        "  ```\n",
        "- **–ü–æ–≤–æ—Ä–æ—Ç:**\n",
        "  ```python\n",
        "  rotated_img = img.rotate(45)  # –ü–æ–≤–æ—Ä–æ—Ç –Ω–∞ 45 –≥—Ä–∞–¥—É—Å–æ–≤\n",
        "  ```\n",
        "- **–¶–≤–µ—Ç–æ–≤—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:**\n",
        "  ```python\n",
        "  gray_img = img.convert('L')  # –í –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Äî –∫–∞–∫ –∫–∞—Ä—Ç–∞, –≥–¥–µ –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å ‚Äî —Ç–æ—á–∫–∞ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∏ —Ü–≤–µ—Ç–æ–º."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé• –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ\n",
        "- **–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–∏–¥–µ–æ?** –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–¥—Ä–æ–≤ —Å —á–∞—Å—Ç–æ—Ç–æ–π –∫–∞–¥—Ä–æ–≤ (fps).\n",
        "- **–ö–ª—é—á–µ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏:**\n",
        "  - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤.\n",
        "  - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü).\n",
        "  - –°–ª–∏—è–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –≤–∏–¥–µ–æ.\n",
        "- **–ü—Ä–∏–º–µ—Ä: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é OpenCV**\n",
        "  ```python\n",
        "  import cv2\n",
        "  video = cv2.VideoCapture('video.mp4')\n",
        "  frame_count = 0\n",
        "  while True:\n",
        "      ret, frame = video.read()\n",
        "      if not ret:\n",
        "          break\n",
        "      cv2.imwrite(f'frames/frame_{frame_count}.jpg', frame)\n",
        "      frame_count += 1\n",
        "  video.release()\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –í–∏–¥–µ–æ ‚Äî –∫–∞–∫ –∞–Ω–∏–º–∞—Ü–∏—è, –≥–¥–µ –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
        "- **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–ª–æ–≤–∞ –∏–ª–∏ –ø–æ–¥—Å–ª–æ–≤–∞.\n",
        "  ```python\n",
        "  from nltk.tokenize import word_tokenize\n",
        "  tokens = word_tokenize(\"–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!\")  # ['–ü—Ä–∏–≤–µ—Ç', ',', '–º–∏—Ä', '!']\n",
        "  ```\n",
        "- **–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤:**\n",
        "  ```python\n",
        "  from nltk.corpus import stopwords\n",
        "  filtered = [w for w in tokens if w.lower() not in stopwords.words('russian')]\n",
        "  ```\n",
        "- **–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —á–∏—Å–ª–∞.\n",
        "  - **Bag of Words:** –°—á–µ—Ç—á–∏–∫ —Å–ª–æ–≤.\n",
        "  - **TF-IDF:** –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å —Å–ª–æ–≤.\n",
        "  - **Word Embeddings:** –í–µ–∫—Ç–æ—Ä—ã —Å–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Word2Vec, GloVe).\n",
        "- **–ü—Ä–∏–º–µ—Ä:**\n",
        "  ```python\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  X = vectorizer.fit_transform([\"—Ç–µ–∫—Å—Ç 1\", \"—Ç–µ–∫—Å—Ç 2\"])\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –¢–µ–∫—Å—Ç ‚Äî –∫–∞–∫ —Å–ø–∏—Å–æ–∫ –ø–æ–∫—É–ø–æ–∫, –≥–¥–µ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ ‚Äî —ç–ª–µ–º–µ–Ω—Ç, –∞ TF-IDF ‚Äî –µ–≥–æ –≤–∞–∂–Ω–æ—Å—Ç—å –¥–ª—è —Ä–µ—Ü–µ–ø—Ç–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ –ü—Ä–∞–∫—Ç–∏–∫–∞: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
        "### –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "img = Image.open('example.jpg')\n",
        "print(\"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\", img.size)\n",
        "\n",
        "# –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞\n",
        "resized_img = img.resize((200, 200))\n",
        "\n",
        "# –í –≥—Ä–∞–¥–∞—Ü–∏—è—Ö —Å–µ—Ä–æ–≥–æ\n",
        "gray_img = resized_img.convert('L')\n",
        "plt.imshow(gray_img, cmap='gray')\n",
        "plt.title('–ì—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé• –ü—Ä–∞–∫—Ç–∏–∫–∞: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ\n",
        "### –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# –û—Ç–∫—Ä—ã—Ç–∏–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞\n",
        "video = cv2.VideoCapture('video.mp4')\n",
        "frame_count = 0\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    cv2.imwrite(f'frames/frame_{frame_count}.jpg', frame)\n",
        "    frame_count += 1\n",
        "video.release()\n",
        "print(f'–ò–∑–≤–ª–µ—á–µ–Ω–æ {frame_count} –∫–∞–¥—Ä–æ–≤')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤\n",
        "```python\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤\n",
        "for filename in os.listdir('frames'):\n",
        "    if filename.endswith('.jpg'):\n",
        "        img = Image.open(os.path.join('frames', filename))\n",
        "        gray_img = img.convert('L')\n",
        "        gray_img.save(os.path.join('processed_frames', filename))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÑ –ü—Ä–∞–∫—Ç–∏–∫–∞: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
        "### –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞\n",
        "text = \"–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –ø—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ù—É–∂–Ω–æ —É–±—Ä–∞—Ç—å —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è.\"\n",
        "\n",
        "# –û—á–∏—Å—Ç–∫–∞\n",
        "tokens = word_tokenize(text.lower())\n",
        "filtered = [w for w in tokens if w.isalpha() and w not in stopwords.words('russian')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –®–∞–≥ 2: –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform([\"—Ç–µ–∫—Å—Ç 1\", \"—Ç–µ–∫—Å—Ç 2\", \"–¥—Ä—É–≥–æ–π —Ç–µ–∫—Å—Ç\"])\n",
        "y = [0, 1, 0]  # –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
        "new_text = vectorizer.transform([\"–Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç\"])\n",
        "print(model.predict(new_text))  # [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ\n",
        "- **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞.\n",
        "- **–í–∏–¥–µ–æ:** –ê–Ω–∞–ª–∏–∑ –¥–µ–π—Å—Ç–≤–∏–π, –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.\n",
        "- **–¢–µ–∫—Å—Ç:** –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, —á–∞—Ç-–±–æ—Ç—ã, –ø–µ—Ä–µ–≤–æ–¥.\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî –∫–∞–∫ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –≤–∏–¥–µ–æ ‚Äî –∫–∞–∫ —Ñ–∏–ª—å–º—ã, —Ç–µ–∫—Å—Ç ‚Äî –∫–∞–∫ –∫–Ω–∏–≥–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "**–ó–∞–¥–∞—á–∞ 1:** –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –≤–∏–¥–µ–æ: –∏–∑–≤–ª–µ–∫–∏—Ç–µ –∫–∞–¥—Ä—ã, –∏–∑–º–µ–Ω–∏—Ç–µ –∏—Ö —Ä–∞–∑–º–µ—Ä –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ.\n",
        "**–ó–∞–¥–∞—á–∞ 2:** –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ç–∑—ã–≤—ã –æ —Ñ–∏–ª—å–º–∞—Ö):\n",
        "- –û—á–∏—Å—Ç–∏—Ç–µ —Ç–µ–∫—Å—Ç.\n",
        "- –í–µ–∫—Ç–æ—Ä–∏–∑—É–π—Ç–µ –µ–≥–æ.\n",
        "- –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
        "- –ù–∞–ø–∏—à–∏—Ç–µ –æ—Ç—á–µ—Ç (200‚Äì300 —Å–ª–æ–≤), –≥–¥–µ:\n",
        "  - –û–ø–∏—à–∏—Ç–µ, –∫–∞–∫ –≤—ã –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ –¥–∞–Ω–Ω—ã–µ.\n",
        "  - –°—Ä–∞–≤–Ω–∏—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –¥–æ –∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.\n",
        "  - –û–±—ä—è—Å–Ω–∏—Ç–µ, –ø–æ—á–µ–º—É —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –º–µ—à–∞—é—Ç.\n",
        "  - –ü—Ä–∏–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã, –≥–¥–µ —ç—Ç–∏ –º–µ—Ç–æ–¥—ã –ø–æ–ª–µ–∑–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–∞—Ç-–±–æ—Ç—ã, –∞–Ω–∞–ª–∏–∑ —Å–æ—Ü—Å–µ—Ç–µ–π)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤\n",
        "video = cv2.VideoCapture('video.mp4')\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    cv2.imwrite(f'frames/frame_{frame_count}.jpg', frame)\n",
        "    frame_count += 1\n",
        "video.release()\n",
        "print(f'–ò–∑–≤–ª–µ—á–µ–Ω–æ {frame_count} –∫–∞–¥—Ä–æ–≤')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤\n",
        "for filename in os.listdir('frames'):\n",
        "    if filename.endswith('.jpg'):\n",
        "        img = Image.open(os.path.join('frames', filename))\n",
        "        # –î–æ–±–∞–≤—å—Ç–µ —Å—é–¥–∞ –∫–æ–¥ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞\n",
        "        # resized_img = ...\n",
        "        # gray_img = ...\n",
        "        # gray_img.save(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.sport.baseball'])\n",
        "X_train = newsgroups.data\n",
        "y_train = newsgroups.target\n",
        "\n",
        "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û—Ü–µ–Ω–∫–∞\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.sport.baseball'])\n",
        "X_test_vec = vectorizer.transform(newsgroups_test.data)\n",
        "accuracy = accuracy_score(newsgroups_test.target, model.predict(X_test_vec))\n",
        "print(f'Accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é\n",
        "- **–ó–∞–¥–∞—á–∞ 1:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `cv2.resize()` –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–¥—Ä–æ–≤.\n",
        "- **–ó–∞–¥–∞—á–∞ 2:** –î–ª—è —Ç–µ–∫—Å—Ç–∞ —É–±–µ—Ä–∏—Ç–µ —Ü–∏—Ñ—Ä—ã –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è.\n",
        "- **–ü–æ–¥—Å–∫–∞–∑–∫–∞:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `os.makedirs()` –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–ø–æ–∫ –ø–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
