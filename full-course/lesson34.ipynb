{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† –£—Ä–æ–∫ 34: –û—Å–Ω–æ–≤—ã NLP ‚Äî —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è, word embeddings, RNN, LSTM\n",
        "**–¶–µ–ª—å —É—Ä–æ–∫–∞:** –ü–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP), –Ω–∞—É—á–∏—Ç—å—Å—è —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å word embeddings, —Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (RNN, LSTM) –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤.\n",
        "\n",
        "## üìå –ß—Ç–æ —Ç–∞–∫–æ–µ NLP?\n",
        "- **NLP (Natural Language Processing)** ‚Äî —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º –ø–æ–Ω–∏–º–∞—Ç—å, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç.\n",
        "- **–ó–∞—á–µ–º?** –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤ —á–∞—Ç-–±–æ—Ç–∞—Ö, –ø–µ—Ä–µ–≤–æ–¥–∞—Ö, –∞–Ω–∞–ª–∏–∑–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏.\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç ‚Äî —ç—Ç–æ —è–∑—ã–∫, —Ç–æ NLP ‚Äî —ç—Ç–æ –∫–∞–∫ —É—á–∏—Ç—å —è–∑—ã–∫, —Ä–∞–∑–±–∏–≤–∞—è –µ–≥–æ –Ω–∞ —Å–ª–æ–≤–∞, —Ñ—Ä–∞–∑—ã –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è [[5]]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß± –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è: —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏\n",
        "- **–ß—Ç–æ —ç—Ç–æ?** –ü—Ä–æ—Ü–µ—Å—Å —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞, –ø–æ–¥—Å–ª–æ–≤–∞, —Å–∏–º–≤–æ–ª—ã).\n",
        "- **–ó–∞—á–µ–º?** –ß—Ç–æ–±—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ML.\n",
        "- **–ú–µ—Ç–æ–¥—ã:**\n",
        "  - **Word-level:** –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤–∞–º.\n",
        "  - **Character-level:** –ü–æ —Å–∏–º–≤–æ–ª–∞–º.\n",
        "  - **Subword-level:** –ü–æ –ø–æ–¥—Å–ª–æ–≤–∞–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, BPE).\n",
        "- **–ü—Ä–∏–º–µ—Ä:**\n",
        "  ```python\n",
        "  from nltk.tokenize import word_tokenize\n",
        "  tokens = word_tokenize(\"–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!\")  # ['–ü—Ä–∏–≤–µ—Ç', ',', '–º–∏—Ä', '!']\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è ‚Äî –∫–∞–∫ —Ä–∞–∑—Ä–µ–∑–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫—É—Å–æ—á–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ [[3]]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìê Word Embeddings: –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤ –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–æ–≤\n",
        "- **–ß—Ç–æ —ç—Ç–æ?** –°–ª–æ–≤–∞ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã, –≥–¥–µ –±–ª–∏–∑–∫–∏–µ —Å–ª–æ–≤–∞ –∏–º–µ—é—Ç –±–ª–∏–∑–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã.\n",
        "- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:** –°–æ—Ö—Ä–∞–Ω—è—é—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"–∫–æ—Ä–æ–ª—å\" ‚Äî \"–º—É–∂—á–∏–Ω–∞\" + \"–∂–µ–Ω—â–∏–Ω–∞\" ‚âà \"–∫–æ—Ä–æ–ª–µ–≤–∞\").\n",
        "- **–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–µ—Ç–æ–¥—ã:**\n",
        "  - **Word2Vec:** –û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Å–µ–¥–Ω–∏—Ö —Å–ª–æ–≤.\n",
        "  - **GloVe:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –∫–æ-–≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Å–ª–æ–≤.\n",
        "  - **FastText:** –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ–¥—Å–ª–æ–≤–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è.\n",
        "- **–ü—Ä–∏–º–µ—Ä:**\n",
        "  ```python\n",
        "  from gensim.models import Word2Vec\n",
        "  model = Word2Vec(sentences=[[\"—è\", \"–ª—é–±–ª—é\", \"–ø–∏—Ç–æ–Ω\"], [\"–ø–∏—Ç–æ–Ω\", \"‚Äî\", \"–º–æ–π\", \"–ª—é–±–∏–º—ã–π\", \"—è–∑—ã–∫\"]], vector_size=100, window=5, min_count=1)\n",
        "  print(model.wv[\"–ø–∏—Ç–æ–Ω\"][:10])  # –í–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"–ø–∏—Ç–æ–Ω\"\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** Word embeddings ‚Äî –∫–∞–∫ –∫–∞—Ä—Ç–∞, –≥–¥–µ –±–ª–∏–∑–∫–∏–µ —Å–ª–æ–≤–∞ –Ω–∞—Ö–æ–¥—è—Ç—Å—è —Ä—è–¥–æ–º [[3]]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ RNN (Recurrent Neural Networks)\n",
        "- **–ß—Ç–æ —ç—Ç–æ?** –ù–µ–π—Ä–æ—Å–µ—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –ø–µ—Ä–µ–¥–∞–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É.\n",
        "- **–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç?** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç **hidden state** –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
        "- **–ü—Ä–æ–±–ª–µ–º–∞:** –ò—Å—á–µ–∑–∞—é—â–∏–π/–≤–∑—Ä—ã–≤–∞—é—â–∏–π—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç ‚Äî RNN –∑–∞–±—ã–≤–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ.\n",
        "- **–ü—Ä–∏–º–µ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**\n",
        "  ```python\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "  \n",
        "  model = Sequential([\n",
        "      SimpleRNN(64, input_shape=(timesteps, features)),\n",
        "      Dense(1)\n",
        "  ])\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** RNN ‚Äî –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π —á–∏—Ç–∞–µ—Ç –∫–Ω–∏–≥—É, –Ω–æ –∑–∞–±—ã–≤–∞–µ—Ç –Ω–∞—á–∞–ª–æ –≥–ª–∞–≤—ã –∫ –∫–æ–Ω—Ü—É [[6]]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† LSTM (Long Short-Term Memory)\n",
        "- **–ß—Ç–æ —ç—Ç–æ?** RNN —Å –≤–µ–Ω—Ç–∏–ª—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—Ç, —á—Ç–æ –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å, –∞ —á—Ç–æ –∑–∞–±—ã–≤–∞—Ç—å.\n",
        "- **–í–µ–Ω—Ç–∏–ª–∏:**\n",
        "  - **Input Gate:** –ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –ø–∞–º—è—Ç—å.\n",
        "  - **Forget Gate:** –ß—Ç–æ —É–¥–∞–ª–∏—Ç—å –∏–∑ –ø–∞–º—è—Ç–∏.\n",
        "  - **Output Gate:** –ß—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.\n",
        "- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**\n",
        "  - –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∏—Å—á–µ–∑–∞—é—â–µ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞.\n",
        "  - –ú–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
        "- **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**\n",
        "  - –°–ª–æ–∂–Ω–µ–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ–π RNN.\n",
        "  - –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±—É—á–∞–µ—Ç—Å—è.\n",
        "- **–ü—Ä–∏–º–µ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**\n",
        "  ```python\n",
        "  from tensorflow.keras.layers import LSTM\n",
        "  model = Sequential([\n",
        "      LSTM(64, input_shape=(timesteps, features)),\n",
        "      Dense(1)\n",
        "  ])\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** LSTM ‚Äî –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫ —Å –±–ª–æ–∫–Ω–æ—Ç–æ–º: –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ–µ, —Å—Ç–∏—Ä–∞–µ—Ç –Ω–µ–Ω—É–∂–Ω–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω–æ–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ [[6]]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ –ü—Ä–∞–∫—Ç–∏–∫–∞: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å LSTM\n",
        "### –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "X_train = pad_sequences(X_train, maxlen=500)\n",
        "X_test = pad_sequences(X_test, maxlen=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å Embedding –∏ LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(10000, 128),  # 10,000 —Å–ª–æ–≤, 128-–º–µ—Ä–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
        "    LSTM(128),  # 128 –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
        "    Dense(1, activation='sigmoid')  # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –®–∞–≥ 3: –ö–æ–º–ø–∏–ª—è—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                  epochs=5,\n",
        "                  batch_size=128,\n",
        "                  validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –®–∞–≥ 4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy –ø–æ —ç–ø–æ—Ö–∞–º')\n",
        "plt.xlabel('–≠–ø–æ—Ö–∏')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ RNN –∏ LSTM\n",
        "- **RNN:** –ü—Ä–æ—Å—Ç–æ–π, –Ω–æ –±—ã—Å—Ç—Ä–æ –∑–∞–±—ã–≤–∞–µ—Ç.\n",
        "- **LSTM:** –í–µ–Ω—Ç–∏–ª–∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—Ç –ø–∞–º—è—Ç—å, –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –¥–ª–∏–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏.\n",
        "- **–ü—Ä–∏–º–µ—Ä:**\n",
        "  ```python\n",
        "  from tensorflow.keras.layers import SimpleRNN\n",
        "  rnn_model = Sequential([\n",
        "      Embedding(10000, 128),\n",
        "      SimpleRNN(128),\n",
        "      Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** RNN ‚Äî –∫–∞–∫ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å, LSTM ‚Äî –∫–∞–∫ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è, –≥–¥–µ –º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å –≤–∞–∂–Ω–æ–µ –≤ –±–ª–æ–∫–Ω–æ—Ç."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Embedding?\n",
        "- **Embedding:** –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ª–æ–≤–∞ –≤ –ø–ª–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã.\n",
        "- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**\n",
        "  - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É.\n",
        "  - –£–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å.\n",
        "- **–ü—Ä–∏–º–µ—Ä:**\n",
        "  ```python\n",
        "  from tensorflow.keras.layers import Embedding\n",
        "  embedding = Embedding(input_dim=10000, output_dim=128)\n",
        "  ```\n",
        "- **input_dim:** –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤.\n",
        "- **output_dim:** –†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞.\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** Embedding ‚Äî –∫–∞–∫ –∫–∞—Ä—Ç–∞ –º–µ—Ç—Ä–æ, –≥–¥–µ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ ‚Äî —Å—Ç–∞–Ω—Ü–∏—è —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìâ –ß—Ç–æ —Ç–∞–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ –∫–∞–∫ –µ–≥–æ –∏–∑–±–µ–∂–∞—Ç—å?\n",
        "- **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (Overfitting):** –ú–æ–¥–µ–ª—å –∏–¥–µ–∞–ª—å–Ω–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–æ –ø–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö.\n",
        "- **–ü—Ä–∏—á–∏–Ω—ã:**\n",
        "  - –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ–π—Ä–æ–Ω–æ–≤.\n",
        "  - –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö.\n",
        "- **–ö–∞–∫ –±–æ—Ä–æ—Ç—å—Å—è?**\n",
        "  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Dropout.\n",
        "  - –£–º–µ–Ω—å—à–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
        "  - –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é.\n",
        "- **–ü—Ä–∏–º–µ—Ä:**\n",
        "  ```python\n",
        "  from tensorflow.keras.layers import Dropout\n",
        "  model = Sequential([\n",
        "      Embedding(10000, 128),\n",
        "      LSTM(128),\n",
        "      Dropout(0.5),\n",
        "      Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** Dropout ‚Äî –∫–∞–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∫–æ–º–∞–Ω–¥—ã –±–µ–∑ –æ–¥–Ω–æ–≥–æ –∏–≥—Ä–æ–∫–∞: –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É—á–∞—Ç—Å—è –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã?\n",
        "- **GridSearchCV:** –ü–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π.\n",
        "- **RandomizedSearchCV:** –°–ª—É—á–∞–π–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä (–±—ã—Å—Ç—Ä–µ–µ, —á–µ–º GridSearch).\n",
        "- **–ü—Ä–∏–º–µ—Ä:**\n",
        "  ```python\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  param_grid = {'units': [64, 128], 'dropout_rate': [0.3, 0.5]}\n",
        "  grid = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
        "  grid.fit(X_train, y_train)\n",
        "  ```\n",
        "- **–ê–Ω–∞–ª–æ–≥–∏—è:** –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Äî –∫–∞–∫ –ø–æ–∏—Å–∫ –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —Ä–µ—Ü–µ–ø—Ç–∞ —á–µ—Ä–µ–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞–º–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "**–ó–∞–¥–∞—á–∞ 1:** –ò–∑–º–µ–Ω–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É LSTM:\n",
        "- –£–≤–µ–ª–∏—á—å—Ç–µ —á–∏—Å–ª–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ 256.\n",
        "- –î–æ–±–∞–≤—å—Ç–µ –µ—â—ë –æ–¥–∏–Ω LSTM(64).\n",
        "- –ö–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è `val_accuracy`?\n",
        "- –ù–∞—Ä–∏—Å—É–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è.\n",
        "- –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ confusion matrix –¥–ª—è –Ω–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "**–ó–∞–¥–∞—á–∞ 2:** –ü–æ–ø—Ä–æ–±—É–π—Ç–µ RNN –≤–º–µ—Å—Ç–æ LSTM –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç—å. –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# –ò–∑–º–µ–Ω–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
        "modified_model = Sequential([\n",
        "    Embedding(10000, 128),\n",
        "    LSTM(256),\n",
        "    Dropout(0.5),\n",
        "    LSTM(64),  # –î–æ–±–∞–≤–ª–µ–Ω –µ—â—ë –æ–¥–∏–Ω LSTM\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û–±—É—á–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "modified_model.compile(optimizer='adam',\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "history = modified_model.fit(X_train, y_train, \n",
        "                         epochs=5,\n",
        "                         batch_size=128,\n",
        "                         validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å RNN\n",
        "rnn_model = Sequential([\n",
        "    Embedding(10000, 128),\n",
        "    SimpleRNN(128),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "rnn_model.compile(optimizer='adam',\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "rnn_history = rnn_model.fit(X_train, y_train, \n",
        "                          epochs=5,\n",
        "                          batch_size=128,\n",
        "                          validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['val_accuracy'], label='LSTM (–∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π)')\n",
        "plt.plot(rnn_history.history['val_accuracy'], label='RNN')\n",
        "plt.legend()\n",
        "plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏')\n",
        "plt.xlabel('–≠–ø–æ—Ö–∏')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é\n",
        "- **–ó–∞–¥–∞—á–∞ 1:** –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –∏ Dropout.\n",
        "- **–ó–∞–¥–∞—á–∞ 2:** –°–ª–µ–¥–∏—Ç–µ –∑–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º ‚Äî –µ—Å–ª–∏ `val_accuracy` –Ω–∏–∂–µ `accuracy`, —É–º–µ–Ω—å—à–∏—Ç–µ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏.\n",
        "- **–ü–æ–¥—Å–∫–∞–∑–∫–∞:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `model.summary()` –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
